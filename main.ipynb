{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>total_cases_per_million</th>\n",
       "      <th>total_deaths_per_million</th>\n",
       "      <th>icu_patients</th>\n",
       "      <th>hosp_patients</th>\n",
       "      <th>weekly_hosp_admissions</th>\n",
       "      <th>daily_case_change_rate</th>\n",
       "      <th>daily_death_change_rate</th>\n",
       "      <th>hospitalization_rate</th>\n",
       "      <th>icu_rate</th>\n",
       "      <th>case_fatality_rate</th>\n",
       "      <th>7day_avg_new_cases</th>\n",
       "      <th>7day_avg_new_deaths</th>\n",
       "      <th>hospitalization_need</th>\n",
       "      <th>icu_requirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>3853351.0</td>\n",
       "      <td>60012.0</td>\n",
       "      <td>145801.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>11390.679</td>\n",
       "      <td>430.994</td>\n",
       "      <td>11458.0</td>\n",
       "      <td>42195.0</td>\n",
       "      <td>30552.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.095021</td>\n",
       "      <td>0.297352</td>\n",
       "      <td>3.783746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>3911870.0</td>\n",
       "      <td>58519.0</td>\n",
       "      <td>146668.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>11563.663</td>\n",
       "      <td>433.557</td>\n",
       "      <td>12487.0</td>\n",
       "      <td>46107.0</td>\n",
       "      <td>31352.0</td>\n",
       "      <td>1.518652</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>1.178643</td>\n",
       "      <td>0.319208</td>\n",
       "      <td>3.749307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>3975206.0</td>\n",
       "      <td>63336.0</td>\n",
       "      <td>147861.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>11750.887</td>\n",
       "      <td>437.084</td>\n",
       "      <td>13916.0</td>\n",
       "      <td>47834.0</td>\n",
       "      <td>31679.0</td>\n",
       "      <td>1.619072</td>\n",
       "      <td>0.813402</td>\n",
       "      <td>1.203309</td>\n",
       "      <td>0.350070</td>\n",
       "      <td>3.719581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>4047622.0</td>\n",
       "      <td>72416.0</td>\n",
       "      <td>149052.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>11964.952</td>\n",
       "      <td>440.604</td>\n",
       "      <td>13627.0</td>\n",
       "      <td>46748.0</td>\n",
       "      <td>31870.0</td>\n",
       "      <td>1.821692</td>\n",
       "      <td>0.805486</td>\n",
       "      <td>1.154950</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>3.682458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-25</td>\n",
       "      <td>4120764.0</td>\n",
       "      <td>73142.0</td>\n",
       "      <td>150306.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>12181.163</td>\n",
       "      <td>444.311</td>\n",
       "      <td>14402.0</td>\n",
       "      <td>51831.0</td>\n",
       "      <td>32804.0</td>\n",
       "      <td>1.807036</td>\n",
       "      <td>0.841317</td>\n",
       "      <td>1.257801</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>3.647527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  total_cases  new_cases  total_deaths  new_deaths  \\\n",
       "0  2020-07-21    3853351.0    60012.0      145801.0       932.0   \n",
       "1  2020-07-22    3911870.0    58519.0      146668.0       867.0   \n",
       "2  2020-07-23    3975206.0    63336.0      147861.0      1193.0   \n",
       "3  2020-07-24    4047622.0    72416.0      149052.0      1191.0   \n",
       "4  2020-07-25    4120764.0    73142.0      150306.0      1254.0   \n",
       "\n",
       "   total_cases_per_million  total_deaths_per_million  icu_patients  \\\n",
       "0                11390.679                   430.994       11458.0   \n",
       "1                11563.663                   433.557       12487.0   \n",
       "2                11750.887                   437.084       13916.0   \n",
       "3                11964.952                   440.604       13627.0   \n",
       "4                12181.163                   444.311       14402.0   \n",
       "\n",
       "   hosp_patients  weekly_hosp_admissions  daily_case_change_rate  \\\n",
       "0        42195.0                 30552.0                     NaN   \n",
       "1        46107.0                 31352.0                1.518652   \n",
       "2        47834.0                 31679.0                1.619072   \n",
       "3        46748.0                 31870.0                1.821692   \n",
       "4        51831.0                 32804.0                1.807036   \n",
       "\n",
       "   daily_death_change_rate  hospitalization_rate  icu_rate  \\\n",
       "0                      NaN              1.095021  0.297352   \n",
       "1                 0.594646              1.178643  0.319208   \n",
       "2                 0.813402              1.203309  0.350070   \n",
       "3                 0.805486              1.154950  0.336667   \n",
       "4                 0.841317              1.257801  0.349498   \n",
       "\n",
       "   case_fatality_rate  7day_avg_new_cases  7day_avg_new_deaths  \\\n",
       "0            3.783746                 NaN                  NaN   \n",
       "1            3.749307                 NaN                  NaN   \n",
       "2            3.719581                 NaN                  NaN   \n",
       "3            3.682458                 NaN                  NaN   \n",
       "4            3.647527                 NaN                  NaN   \n",
       "\n",
       "  hospitalization_need icu_requirement  \n",
       "0                 High            High  \n",
       "1                 High            High  \n",
       "2                 High            High  \n",
       "3                 High            High  \n",
       "4                 High            High  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "df = pd.read_csv(\"owid_covid_data_us_subset.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find precision, recall, and F1 score\n",
    "def pre_rec_f1(y_pred, y):\n",
    "    eps = np.finfo(float).eps\n",
    "    num_cls = len(np.unique(y))\n",
    "    tp_sum, fp_sum, fn_sum, f1_sum = 0, 0, 0, 0\n",
    "    tps, fps, fns, pre, rec, f1s = [], [], [], [], [], []\n",
    "    for i in range(num_cls):\n",
    "        y_pred_i = y_pred == i\n",
    "        y_i = y == i\n",
    "        tp = np.logical_and(y_pred_i, y_i).sum()\n",
    "        fp = np.logical_and(y_pred_i, (~y_i)).sum()\n",
    "        fn = np.logical_and((~y_pred_i), y_i).sum()\n",
    "        tp_sum += tp\n",
    "        fp_sum += fp\n",
    "        fn_sum += fn\n",
    "        f1 = (2 * tp) / (2 * tp + fp + fn + eps)\n",
    "        f1_sum += f1\n",
    "        pre.append(tp / (tp + fp + eps))\n",
    "        rec.append(tp / (tp + fn + eps))\n",
    "        tps.append(tp)\n",
    "        fps.append(fp)\n",
    "        fns.append(fn)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    macrof1 = f1_sum / (num_cls + eps)\n",
    "    microf1 = (2 * tp_sum) / (2 * tp_sum + fp_sum + fn_sum + eps)\n",
    "    return macrof1, microf1, tps, fps, fns, pre, rec, f1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Cleaning and Exploratory Analysis.\n",
    "- Cleaning missing values, removing duplicates, and standardizing formats on original data and original data set.\n",
    "- Exploratory analysis to identify trends, patterns, and anomalies.\n",
    "- Visualization using Matplotlib and Seaborn.\n",
    "- Line charts for time-series trends in total_cases, total_deaths, and hospitalization_rate.\n",
    "- Histograms and boxplots for ICU rates and hospitalization distributions.\n",
    "- Use StandardScaler to normalize the features before applying a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "#Code for task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Correlation and Statistical Analysis (Data subset)\n",
    "- Compute Pearson correlation coefficients between numerical variables, focusing on icu_requirement and other derived features.\n",
    "- Create a heatmap to visualize the full correlation matrix, highlighting features with strong relationships (e.g., correlations > Â±0.5)\n",
    "- Scatter plots with regression lines for correlated features.\n",
    "- Use Chi-Square tests to examine associations between categorical variables\n",
    "- Tables summarizing ANOVA/Kruskal-Wallis results, with p-values and effect sizes for key variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Predictive Modeling: Decision Tree (Data Subset)\n",
    "- Perform 5-fold cross-validation for each of the 5 max depths and compute accuracy, precision, recall, macro-F1 and micro-F1 and find which max depth works best on predicting the icu requirement.\n",
    "- Testing max_depth with 3, 5, 10, 15, 20.\n",
    "- Use features like icu_rate, case_fatality_rate, hospitalization_rate, etc., to predict how many ICU patients will be needed on a given day.\n",
    "- Visualize the overall best Decision Tree for ICU Patient Prediction and analyze the trade off between different tree depth choices (General Geni/Entropy).\n",
    "- Performance metric comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Predictive Modeling: KNN (Data Subset)\n",
    "- Perform 5-fold cross-validation for each of the 5 kernel functions and compute accuracy, precision, recall, macro-F1, and micro-F1 on predicting the icu requirement and research which kernel function works the best on predicting the icu requirement.\n",
    "- Using different numbers of neighbors (e.g. 2, 5, 10, 50)\n",
    "- Analyze how the different numbers of neighbors affect the performance of the model.\n",
    "- Analyze the trade-off between different numbers of neighbor's choices.\n",
    "- Performance metric comparisons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Predictive Modeling: SVM (Data Subset)\n",
    "- Perform 5-fold cross-validation for each of the 4 kernel functions and compute accuracy, precision, recall, macro-F1, and micro-F1 on predicting the icu requirement and research which kernel function works the best.\n",
    "- Using different kernels: Linear, Polynomials, RBF, Sigmoids.\n",
    "- Compare kernel function performances and explain their impact.\n",
    "- Analyze trade-offs between different kernel choices.\n",
    "- Performance metric comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Model Comparison Methodology (Data Subset)\n",
    "- Compare best-performing models from Decision Tree, KNN, and SVM.\n",
    "- Training Time: Record and analyze the computational complexity and efficiency of each model.\n",
    "- Performance Metrics: Compute and compare accuracy, precision, recall, macro-F1, and micro-F1 across models.\n",
    "- Analyze the outcome of the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Regional Pattern Analysis and Comparison (On the continent attribute of the Full data set)\n",
    "- Investigate patterns and trends across different regions or states in the original full dataset.\n",
    "- Segment the data by geographical regions (continent).\n",
    "- Use clustering techniques (e.g., K-Means or hierarchical clustering) to group regions with similar COVID-19 characteristics,  total_cases, total_deaths, hosp_patients.etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 8: Advanced Feature Derivation and Preprocessing (Full dataset)\n",
    "- Generate time-based features such as infection growth rates, recovery rates, and rolling averages.\n",
    "- Apply quantile-based discretization for continuous variables (e.g., hospitalization rates).\n",
    "- Use Principal Component Analysis (PCA) to reduce dimensionality and derive composite features (e.g., healthcare capacity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Time Series Forecasting Using Deep Learning\n",
    "- Forecast key metrics (e.g., ICU requirements, total cases) using state-of-the-art time series models.\n",
    "- Implement Long Short-Term Memory (LSTM) networks to capture temporal dependencies.\n",
    "- Evaluate models using metrics such as Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
