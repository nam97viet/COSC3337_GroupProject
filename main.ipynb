{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Cleaning and Exploratory Analysis.\n",
    "- Cleaning missing values, removing duplicates, and standardizing formats on original data and original data set.\n",
    "- Exploratory analysis to identify trends, patterns, and anomalies.\n",
    "- Visualization using Matplotlib and Seaborn.\n",
    "- Line charts for time-series trends in total_cases, total_deaths, and hospitalization_rate.\n",
    "- Histograms and boxplots for ICU rates and hospitalization distributions.\n",
    "- Use StandardScaler to normalize the features before applying a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "#Code for task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Correlation and Statistical Analysis (Data subset)\n",
    "- Compute Pearson correlation coefficients between numerical variables, focusing on icu_requirement and other derived features.\n",
    "- Create a heatmap to visualize the full correlation matrix, highlighting features with strong relationships (e.g., correlations > Â±0.5)\n",
    "- Scatter plots with regression lines for correlated features.\n",
    "- Use Chi-Square tests to examine associations between categorical variables\n",
    "- Tables summarizing ANOVA/Kruskal-Wallis results, with p-values and effect sizes for key variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Predictive Modeling: Decision Tree (Data Subset)\n",
    "- Perform 5-fold cross-validation for each of the 5 max depths and compute accuracy, precision, recall, macro-F1 and micro-F1 and find which max depth works best on predicting the icu requirement.\n",
    "- Testing max_depth with 3, 5, 10, 15, 20.\n",
    "- Use features like icu_rate, case_fatality_rate, hospitalization_rate, etc., to predict how many ICU patients will be needed on a given day.\n",
    "- Visualize the overall best Decision Tree for ICU Patient Prediction and analyze the trade off between different tree depth choices (General Geni/Entropy).\n",
    "- Performance metric comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Predictive Modeling: KNN (Data Subset)\n",
    "- Perform 5-fold cross-validation for each of the 5 kernel functions and compute accuracy, precision, recall, macro-F1, and micro-F1 on predicting the icu requirement and research which kernel function works the best on predicting the icu requirement.\n",
    "- Using different numbers of neighbors (e.g. 2, 5, 10, 50)\n",
    "- Analyze how the different numbers of neighbors affect the performance of the model.\n",
    "- Analyze the trade-off between different numbers of neighbor's choices.\n",
    "- Performance metric comparisons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Predictive Modeling: SVM (Data Subset)\n",
    "- Perform 5-fold cross-validation for each of the 4 kernel functions and compute accuracy, precision, recall, macro-F1, and micro-F1 on predicting the icu requirement and research which kernel function works the best.\n",
    "- Using different kernels: Linear, Polynomials, RBF, Sigmoids.\n",
    "- Compare kernel function performances and explain their impact.\n",
    "- Analyze trade-offs between different kernel choices.\n",
    "- Performance metric comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Model Comparison Methodology (Data Subset)\n",
    "- Compare best-performing models from Decision Tree, KNN, and SVM.\n",
    "- Training Time: Record and analyze the computational complexity and efficiency of each model.\n",
    "- Performance Metrics: Compute and compare accuracy, precision, recall, macro-F1, and micro-F1 across models.\n",
    "- Analyze the outcome of the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Regional Pattern Analysis and Comparison (On the continent attribute of the Full data set)\n",
    "- Investigate patterns and trends across different regions or states in the original full dataset.\n",
    "- Segment the data by geographical regions (continent).\n",
    "- Use clustering techniques (e.g., K-Means or hierarchical clustering) to group regions with similar COVID-19 characteristics,  total_cases, total_deaths, hosp_patients.etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 8: Advanced Feature Derivation and Preprocessing (Full dataset)\n",
    "- Generate time-based features such as infection growth rates, recovery rates, and rolling averages.\n",
    "- Apply quantile-based discretization for continuous variables (e.g., hospitalization rates).\n",
    "- Use Principal Component Analysis (PCA) to reduce dimensionality and derive composite features (e.g., healthcare capacity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Time Series Forecasting Using Deep Learning\n",
    "- Forecast key metrics (e.g., ICU requirements, total cases) using state-of-the-art time series models.\n",
    "- Implement Long Short-Term Memory (LSTM) networks to capture temporal dependencies.\n",
    "- Evaluate models using metrics such as Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for task 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
